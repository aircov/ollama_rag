# -*- coding: utf-8 -*-
# @Time    : 2025/3/13 15:05
# @Author  : yaomw
# @Desc    :

import gradio as gr

from rag import RAGPipeline
from utils.ollama_utils import fetch_ollama_models

rag = RAGPipeline()


# æ–°å¢å‡½æ•°ï¼šè·å–ç³»ç»Ÿä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
def get_system_models_info():
    """è¿”å›ç³»ç»Ÿä½¿ç”¨çš„å„ç§æ¨¡å‹ä¿¡æ¯"""
    models_info = {
        "åµŒå…¥æ¨¡å‹": "all-MiniLM-L6-v2",
        "åˆ†å—æ–¹æ³•": "RecursiveCharacterTextSplitter (chunk_size=800, overlap=150)",
        "æ£€ç´¢æ–¹æ³•": "å‘é‡æ£€ç´¢ + BM25æ··åˆæ£€ç´¢ (Î±=0.7)",
        "é‡æ’åºæ¨¡å‹": "äº¤å‰ç¼–ç å™¨ (sentence-transformers/distiluse-base-multilingual-cased-v2)",
        "ç”Ÿæˆæ¨¡å‹": "deepseek-r1 (7B/1.5B)",
        "åˆ†è¯å·¥å…·": "jieba (ä¸­æ–‡åˆ†è¯)"
    }
    return models_info


def process_upload_files(files):
    if not files:
        return "è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶", []
    file_list = rag.load_and_split_documents(files=files)
    
    summary = f"\næ€»è®¡å¤„ç† {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¤„ç†å®Œæˆ"
    
    # å·²å¤„ç†æ–‡ä»¶
    ret = [f"æ–‡ä»¶å: ã€Š{i['key']}ã€‹ï¼Œåˆ†å—æ•°é‡ï¼š{i['doc_count']}" for i in file_list]
    
    return summary, "\n".join(ret)

def process_chat(question, history, enable_web_search, model_choice):
    if history is None:
        history = []
    if not question:
        return "è¯·è¾“å…¥é—®é¢˜", history
    
    # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°å†å²
    history.append((question, ""))
    
    rag.setup_rag_chain(rerank_method="corom", enable_web_search=enable_web_search, model_name=model_choice)


with gr.Blocks() as demo:
    gr.Markdown("# ğŸ§  æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
    
    with gr.Tabs() as tabs:
        # ç¬¬ä¸€ä¸ªé€‰é¡¹å¡ï¼šé—®ç­”å¯¹è¯
        with gr.TabItem("ğŸ’¬ é—®ç­”å¯¹è¯"):
            with gr.Row(equal_height=True):
                # å·¦ä¾§æ“ä½œé¢æ¿ - è°ƒæ•´æ¯”ä¾‹ä¸ºåˆé€‚çš„å¤§å°
                with gr.Column(scale=5, elem_classes="left-panel"):
                    gr.Markdown("## ğŸ“‚ æ–‡æ¡£å¤„ç†åŒº")
                    with gr.Group():
                        file_input = gr.File(
                            label="ä¸Šä¼ æ–‡æ¡£ï¼Œæ”¯æŒpdfã€docxã€txtã€mdã€html",
                            file_types=[],
                            file_count="multiple"
                        )
                        upload_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary")
                        upload_status = gr.Textbox(
                            label="å¤„ç†çŠ¶æ€",
                            interactive=False,
                            lines=2
                        )
                        file_list = gr.Textbox(
                            label="å·²å¤„ç†æ–‡ä»¶",
                            interactive=False,
                            lines=3,
                            elem_classes="file-list"
                        )
                    
                    # å°†é—®é¢˜è¾“å…¥åŒºç§»è‡³å·¦ä¾§é¢æ¿åº•éƒ¨
                    gr.Markdown("## â“ è¾“å…¥é—®é¢˜")
                    with gr.Group():
                        question_input = gr.Textbox(
                            label="è¾“å…¥é—®é¢˜",
                            lines=3,
                            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                            elem_id="question-input"
                        )
                        with gr.Row():
                            # æ·»åŠ è”ç½‘å¼€å…³
                            web_search_checkbox = gr.Checkbox(
                                label="å¯ç”¨è”ç½‘æœç´¢",
                                value=False,
                                info="æ‰“å¼€åå°†åŒæ—¶æœç´¢ç½‘ç»œå†…å®¹ï¼ˆéœ€è¦VPNï¼‰"
                            )
                            
                            # æ·»åŠ æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                            model_choice = gr.Dropdown(
                                choices=fetch_ollama_models(),
                                value="deepseek-r1:14b",
                                label="æ¨¡å‹é€‰æ‹©",
                                info="é€‰æ‹©ä½¿ç”¨çš„æœ¬åœ°æ¨¡å‹",
                                interactive=True
                            )
                        
                        with gr.Row():
                            ask_btn = gr.Button("ğŸ” å¼€å§‹æé—®", variant="primary", scale=2)
                            clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="secondary", elem_classes="clear-button",
                                                  scale=1)
                
                # å³ä¾§å¯¹è¯åŒº - è°ƒæ•´æ¯”ä¾‹
                with gr.Column(scale=7, elem_classes="right-panel"):
                    gr.Markdown("## ğŸ“ å¯¹è¯è®°å½•")
                    
                    # å¯¹è¯è®°å½•æ˜¾ç¤ºåŒº
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯å†å²",
                        height=600,  # å¢åŠ é«˜åº¦
                        elem_classes="chat-container",
                        show_label=False
                    )
                    
                    status_display = gr.HTML("", elem_id="status-display")
                    gr.Markdown("""
                                <div class="footer-note">
                                    *å›ç­”ç”Ÿæˆå¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…<br>
                                    *æ”¯æŒå¤šè½®å¯¹è¯ï¼Œå¯åŸºäºå‰æ–‡ç»§ç»­æé—®
                                </div>
                                """)
        
        # ç¬¬äºŒä¸ªé€‰é¡¹å¡ï¼šåˆ†å—å¯è§†åŒ–
        with gr.TabItem("ğŸ“Š åˆ†å—å¯è§†åŒ–"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("## ğŸ’¡ ç³»ç»Ÿæ¨¡å‹ä¿¡æ¯")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿæ¨¡å‹ä¿¡æ¯å¡ç‰‡
                    models_info = get_system_models_info()
                    with gr.Group(elem_classes="model-card"):
                        gr.Markdown("### æ ¸å¿ƒæ¨¡å‹ä¸æŠ€æœ¯")
                        
                        for key, value in models_info.items():
                            with gr.Row():
                                gr.Markdown(f"**{key}**:", elem_classes="label")
                                gr.Markdown(f"{value}", elem_classes="value")
                
                with gr.Column(scale=2):
                    gr.Markdown("## ğŸ“„ æ–‡æ¡£åˆ†å—ç»Ÿè®¡")
                    refresh_chunks_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ†å—æ•°æ®", variant="primary")
                    chunks_status = gr.Markdown("ç‚¹å‡»æŒ‰é’®æŸ¥çœ‹åˆ†å—ç»Ÿè®¡")
            
            # åˆ†å—æ•°æ®è¡¨æ ¼å’Œè¯¦æƒ…
            with gr.Row():
                chunks_data = gr.Dataframe(
                    headers=["æ¥æº", "åºå·", "å­—ç¬¦æ•°", "åˆ†è¯æ•°", "å†…å®¹é¢„è§ˆ"],
                    elem_classes="chunk-table",
                    interactive=False,
                    wrap=True,
                    row_count=(10, "dynamic")
                )
            
            with gr.Row():
                chunk_detail_text = gr.Textbox(
                    label="åˆ†å—è¯¦æƒ…",
                    placeholder="ç‚¹å‡»è¡¨æ ¼ä¸­çš„è¡ŒæŸ¥çœ‹å®Œæ•´å†…å®¹...",
                    lines=8,
                    elem_classes="chunk-detail-box"
                )
    
    # ç»‘å®šUIäº‹ä»¶
    upload_btn.click(
        process_upload_files,
        inputs=[file_input],
        outputs=[upload_status, file_list],
        show_progress=True
    )
    
    # ç»‘å®šæé—®æŒ‰é’®
    ask_btn.click(
        process_chat,
        inputs=[question_input, chatbot, web_search_checkbox, model_choice],
        outputs=[chatbot, question_input]
    )

if __name__ == "__main__":
    demo.launch()
